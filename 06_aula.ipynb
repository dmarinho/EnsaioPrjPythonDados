{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dioge\\AppData\\Local\\Temp\\ipykernel_35836\\4066906150.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hello\\nAI: How are you?'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"Hello\")\n",
    "memory.chat_memory.add_ai_message(\"How are you?\") \n",
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message(\"Hello\")\n",
    "memory.chat_memory.add_ai_message(\"How are you?\") \n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dioge\\AppData\\Local\\Temp\\ipykernel_35836\\50126539.py:9: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "#Criar uma conversa com memoria\n",
    "\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, my name é Diógenes\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Diógenes! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello, my name é Diógenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name é Diógenes\n",
      "AI: Hello Diógenes! It's nice to meet you. How can I assist you today?\n",
      "Human: When my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Diógenes.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"When my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello, my name é Diógenes\\nAI: Hello Diógenes! It's nice to meet you. How can I assist you today?\\nHuman: When my name?\\nAI: Your name is Diógenes.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dioge\\AppData\\Local\\Temp\\ipykernel_35836\\567507447.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, my name é Diógenes\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Diógenes! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello, my name é Diógenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name é Diógenes\n",
      "AI: Hello Diógenes! It's nice to meet you. How can I assist you today?\n",
      "Human: How are you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you for asking! I'm here and ready to help with any questions or tasks you have. What can I assist you with today, Diógenes?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you?\n",
      "AI: I'm doing well, thank you for asking! I'm here and ready to help with any questions or tasks you have. What can I assist you with today, Diógenes?\n",
      "Human: When my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Diógenes.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"When my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationTokenBufferMemory(llm=chat, max_token_limit=250)\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Me conte uma história de 500 palavras\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro! Esta é uma história sobre uma jovem chamada Sofia que vivia em uma pequena vila na beira de uma floresta mágica. Sofia sempre teve uma grande curiosidade sobre o desconhecido e passava seus dias explorando os arredores da vila.\\n\\nUm dia, enquanto caminhava pela floresta, Sofia encontrou uma antiga fada que lhe disse que ela era a escolhida para uma missão importante. A fada explicou que um terrível mal estava ameaçando a floresta e apenas Sofia poderia detê-lo.\\n\\nEmpolgada com a aventura, Sofia aceitou a missão e partiu em uma jornada cheia de perigos e desafios. Ela enfrentou criaturas místicas, armadilhas traiçoeiras e teve que usar toda sua coragem e inteligência para seguir em frente.\\n\\nNo caminho, Sofia encontrou aliados inesperados, como um sábio mago que a ensinou feitiços poderosos e uma valente guerreira que lutou ao seu lado contra as forças das trevas. Juntos, eles enfrentaram o mal que assolava a floresta e conseguiram derrotá-lo.\\n\\nAo final da aventura, Sofia descobriu que sua coragem e determinação eram seu verdadeiro poder. Ela voltou para sua vila como uma heroína, respeitada por todos e com uma incrível história para contar.\\n\\nE assim, Sofia aprendeu que muitas vezes as maiores jornadas começam com um simples passo no desconhecido. E que, com determinação e amizade, podemos superar qualquer obstáculo que se apresente em nosso caminho.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Me conte uma história de 500 palavras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: resuma a história anterior\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro! Na história anterior, um grupo de astronautas estava em uma missão para explorar um planeta distante. Eles descobriram sinais de vida inteligente e ficaram fascinados com a cultura e tecnologia avançada dos habitantes locais. No entanto, eles também descobriram que havia um conflito em curso entre diferentes facções, o que os colocou em perigo. No final, os astronautas tiveram que encontrar uma maneira de mediar o conflito e garantir sua própria segurança enquanto continuavam com sua missão de descoberta.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"resuma a história anterior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: resuma a história anterior\n",
      "AI: Claro! Na história anterior, um grupo de astronautas estava em uma missão para explorar um planeta distante. Eles descobriram sinais de vida inteligente e ficaram fascinados com a cultura e tecnologia avançada dos habitantes locais. No entanto, eles também descobriram que havia um conflito em curso entre diferentes facções, o que os colocou em perigo. No final, os astronautas tiveram que encontrar uma maneira de mediar o conflito e garantir sua própria segurança enquanto continuavam com sua missão de descoberta.\n",
      "Human: ola\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá! Como posso ajudá-lo hoje?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"ola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dioge\\AppData\\Local\\Temp\\ipykernel_35836\\579693325.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(llm=chat, max_token_limit=250)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationSummaryBufferMemory(llm=chat, max_token_limit=250)\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: meu nome é diógenes\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá, Diógenes! Como posso ajudá-lo hoje?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"meu nome é diógenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: meu nome é diógenes\n",
      "AI: Olá, Diógenes! Como posso ajudá-lo hoje?\n",
      "Human: me conte uma historia de ate 500 palavras\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro, vou me esforçar para contar uma história interessante para você! Era uma vez, em um reino distante, um jovem chamado Lucas que sonhava em se tornar um cavaleiro. Ele treinava duro todos os dias com a espada, o arco e a flecha, na esperança de um dia poder proteger o reino de qualquer perigo que ameaçasse a paz.\\n\\nUm dia, o rei convocou todos os jovens do reino para uma competição de habilidades de combate. O vencedor seria nomeado cavaleiro real e teria a honra de proteger o reino ao lado dos bravos guerreiros. Lucas viu isso como a oportunidade perfeita para realizar seu sonho.\\n\\nDurante a competição, Lucas mostrou grande habilidade e coragem. Ele derrotou todos os seus oponentes com destreza e precisão. Finalmente, chegou a hora da luta final contra o mais temido dos guerreiros do reino, o temível Dragão de Fogo.\\n\\nO Dragão de Fogo era conhecido por sua força e ferocidade. Sua pele escamosa brilhava como chamas, e sua respiração podia incendiar qualquer coisa que tocasse. Lucas sabia que essa seria a maior batalha de sua vida, mas não recuou diante do desafio.\\n\\nCom determinação e coragem, Lucas enfrentou o Dragão de Fogo. A batalha foi intensa, com chamas e espadas se chocando no ar. Mas, no final, Lucas conseguiu derrotar a fera e proteger o reino.\\n\\nO rei estava impressionado com a bravura e habilidade de Lucas e o nomeou cavaleiro real naquela mesma noite. Lucas finalmente realizou seu sonho e jurou proteger o reino com todas as suas forças.\\n\\nE assim, Lucas se tornou um dos maiores cavaleiros que o reino já viu, conhecido por sua coragem, lealdade e determinação. Ele viveu muitas aventuras emocionantes, mas sempre lembraria daquela competição que mudou sua vida para sempre.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"me conte uma historia de ate 500 palavras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: O humano pede para o AI contar uma história de até 500 palavras. O AI começa a contar a história de um jovem chamado Lucas que sonhava em se tornar um cavaleiro e que enfrentou o temível Dragão de Fogo para proteger o reino. Lucas finalmente realizou seu sonho e foi nomeado cavaleiro real, tornando-se um dos maiores guerreiros do reino.\n",
      "Human: qual meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas eu não sei o seu nome. Posso te chamar de humano se você preferir.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"qual meu nome?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
